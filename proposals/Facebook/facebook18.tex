\documentclass[10pt,twocolumn]{article}

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\oddsidemargin  0.0in
	\evensidemargin 0.0in
	\textwidth      6.5in
	\headheight     0.0in
        \headsep        0.0in
	\topmargin      0.0in
	\textheight=9.0in
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{titlesec}

\titleformat*{\section}{\large\bfseries}

\renewcommand{\topfraction}{0.95}
\renewcommand{\textfraction}{0.05}
\renewcommand\floatpagefraction{0.9}

\newcommand{\et}[1]{{\color{blue} {\bf ET:} #1}}

\newcommand{\minisec}[1]{\vspace{2ex}\noindent\textbf{#1}}

\begin{document}
\begin{sloppypar}

\twocolumn[
\begin{center}
\Large
\textbf{Incremental Verification, Gradually}

\vspace{0.5cm}

\normalsize
\textbf{Jonathan Aldrich
(\href{https://dblp.uni-trier.de/pers/hd/a/Aldrich:Jonathan}{DBLP}
/\href{https://scholar.google.com/citations?user=AzHmOtcAAAAJ&hl=en}{GS}),
%
\'Eric Tanter (\href{https://dblp.uni-trier.de/pers/hd/t/Tanter:=Eacute=ric}{DBLP}/\href{https://scholar.google.com/citations?user=d0LISE4AAAAJ}{GS}), 
%
and Joshua Sunshine 
(\href{https://dblp.uni-trier.de/pers/hd/s/Sunshine:Joshua}{DBLP}
/\href{https://scholar.google.com/citations?user=V1texCUAAAAJ&hl=en&oi=ao}{GS})
}

\vspace{0.5cm}

\end{center}]

\section{Scientific Contribution}
\vspace{-2ex}

Scientific advances from the past two decades such as separation logic have resulted in tools such as Infer that are having a profound impact on quality assurance at Facebook and other major companies.  Incrementality is a key enabler of that impact: it allows the analysis tool or its users to select the portion of the code to be verified, making sure that analysis time---and specification time, where relevant---is spent most effectively.  For example, we might want to verify just the changes to the codebase~\cite{StartupsScaleups}, a feature readily supported by Facebook's Infer tool.  Alternatively, we might want to verify properties of one component without specifying and verifying the related properties of surrounding components.  Later on in the development process, we can incrementally extend this verification to other components, one at a time.

This second form of incrementality---adding one component at a time to the body of verified code---remains an open challenge for many forms of static verification. The precondition of a function $f$ might be specified or inferred, but if the caller's precondition is not specified and cannot be inferred successfully, then the tool may not be able to determine whether $f$'s precondition has been established. A developer can address that problem by adding a specification to the caller, but this takes valuable time that the developer may prefer to invest elsewhere---and besides, the caller may itself have a caller, and specifying the whole program at once may be infeasible or impractical.

We have recently proposed \textit{gradual verification}~\cite{baderAl:vmcai2018} to address this problem by smoothly combining static and dynamic verification. When specifications are provided or can be inferred, a component can be verified statically.  Otherwise, dynamic checks are inserted at the boundary between components that are specified and verified on the one hand, and components that are not on the other. Gradual verification is inspired by gradual typing---a technology that in various forms is having major impact in industry, including via Facebook's Hack---and we adapt several key properties of gradual typing research to the verification setting:

\begin{enumerate}[leftmargin=1em]\itemsep0em

\item
In addition to providing specifications for only some components, it is possible to give \textit{partial} specifications anywhere in the code.  For example, the precondition ``? * $x<10$'' means ``This function requires that $x<10$ and it also has other, currently unspecified, requirements.''  Even if ``$x<10$'' alone is not enough to verify a function, if there is some condition that can be plugged in for ``?'' that is sufficient for the function to be verified, the static analyzer will not give an error, but will insert appropriate run-time checks. Dually, if $x<10$ is definitely violated by a client, the analyzer can report a static error.

\item
Gradual verification provides a {\em smooth} continuum between static and dynamic verification, captured by a property known as the \textit{gradual guarantees}~\cite{siekAl:snapl2015}: any relaxation of a legal specification is still a legal specification, and will not result in additional run-time or compile-time errors.  This ensures that programmers can move smoothly from no specifications to full specifications, including all points in between, and will get static/dynamic errors only when the specifications and code they write is somehow inconsistent, not merely because some specifications are missing or incomplete.

\item
Run-time verification checks only the part of a condition that cannot be verified statically, potentially saving substantial run-time overhead compared to always checking the full condition dynamically.  Our approach builds on the Abstracting Gradual Typing approach~\cite{garciaAl:popl2016}, and is also reminiscent of abduction as used in Infer~\cite{Calcagno:2011:CSA:2049697.2049700}.

\end{enumerate}

We believe these properties are key to achieving incremental specification and verification in practice.  Property \#1 allows programmers to specify only the properties they care about and get useful feedback from the tool even with incomplete specifications; more properties can be added incrementally.  Property \#2 ensures that incrementally adding (or removing) specifications will not cause warnings that are spurious in the sense that the added specifications are correct but incomplete; the requirement that developers add specifications until a complete proof is formed is one of the most problematic aspects of many specification-based verification tools.  Property \#3 is important because run-time checks can be quite computationally expensive, so anything we can do to minimize their cost will help us get more dynamic verification out of a fixed computational cost budget.


\section{Proposed Work}
\vspace{-2ex}

Our initial paper on gradual verification~\cite{baderAl:vmcai2018} develops the notions above for a simple Hoare logic; important research needs to be done to fulfill the promise of the idea.
We propose to extend our theory, including the gradual guarantee, to more realistic logics, starting with implicit dynamic frames---an area where we have done some preliminary work already---and then moving to a separation logic with recursive predicates, focusing in particular on the logic used internally within Infer to see if it can be integrated into the gradual verification research agenda.
On a technical level, we propose to handle recursive predicates isorecursively, so that when (un)folding a predicate we reason about (and potentially track at run time) what state is owned by that (un)folding's part of the predicate, and likewise handle any imprecision (i.e. ?'s) in that unfolding of the formula.
These more advanced logics will bring challenges in run time verification, as the dynamic analysis will have to track the portions of the heap owned by different parts of the formula, including subformulas that are framed away during a function call.
An advantage is that we are mainly interested in checking first-order assertions, i.e. such as those typically found in Hoare logic pre- and post-conditions, and recent results in gradual typing suggest that we should be able to get good run time checking performance in this situation~\cite{muehlboeckTate:oopsla2017}.

Once we have a prototype gradual verifier, we plan to investigate whether gradual verification helps developers write good specifications and find bugs more quickly than state of the art, non-gradual tools.
We hypothesize that the ability to provide partial specifications and to defer some checks to run time will be useful in a variety of quality-related tasks.

\section{Routes to Deployment}
\vspace{-2ex}

Although there is prior work hybridizing static and dynamic verification, we published the first exploration of a gradual verification system with the key properties listed above in early 2018, and the limitations in that work prevent it from being immediately deployed in industrial-strength verification tools.  Our goal is to work on those limitations in a simple theoretical and prototype implementation setting in the coming year, supported by a Facebook gift, so that by a year from now, the technology will be advanced enough that it could be experimentally added to tools such as Infer in the following year.

While the obvious application of gradual verification is to add incrementality to tools such as Dafny that are based on programmer-written specifications, we believe that applying gradual verification to more automated tools such as Infer could have even greater dividends, as these tools are more widely used in industry. For example, Infer may be able to come up with a precondition for a function, but may not be able to either prove or disprove that a given caller establishes the precondition.  In such situations, today's tools must choose between giving the programmer a possibly spurious warning or ignoring a potential error. Our gradual verification theory would help Infer decide when to give warnings---e.g. it includes an explicit representation of where a specified or inferred assertion is partial and can use that information to detect definite inconsistencies that may not be obvious without this information.  It can also allow Infer to insert run-time assertions that can be checked in any test cases that exercise the code, making those test cases more likely to find defects.  At the same time, our approach can help minimize the computational cost of those run-time checks.  Gradual verification ideas could be used to enhance Infer's ``modeling'' capability, so that partial models can be given (with the partiality explicit, rather than implicit, again aiding in checking). Finally, gradual verification could provide a way for Infer users to put more explicit specifications in code when desired, making the tool more powerful while still retaining the incrementality properties that Infer already provides.
Co-PI Tanter has a forthcoming paper on gradual liquid type inference~\cite{vazouAl:oopsla2018}, which shows the benefits of the gradual approach in a setting with inference and logical information, much like that of the Infer tool.

\section{Research Team}
\vspace{-2ex}

\textbf{PI Aldrich} has expertise in applied verification for resource logics, as well as the design of usable type systems and analysis tools.  \textbf{Co-PI Tanter} brings expertise in gradual typing, particularly for advanced typing disciplines such as gradual refinement types~\cite{lehmannTanter:popl2017} and gradual liquid inference~\cite{vazouAl:oopsla2018}.  They worked with \textbf{Johannes Bader} to develop the first iteration of gradual verification, which formed Bader's master's thesis.  Bader has been admitted to CMU's Ph.D. program, where he will be advised by Aldrich and (remotely) Tanter, but he deferred for a year, in which he is working at Facebook.  \textbf{Co-PI Sunshine} is an expert on evaluating and improving the usability of programming languages, type systems, and related tools.  We hope that close coordination with Johannes as well as Facebook researchers in related areas, such as Peter O'Hearn, will facilitate collaboration with Facebook and eventual transition of the research ideas into practical use.

\bibliographystyle{abbrv}
\bibliography{gradual}

\end{sloppypar}
\end{document}